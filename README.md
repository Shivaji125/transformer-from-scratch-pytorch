# Transformer From Scratch (PyTorch)

This repository implements the Transformer architecture from scratch using PyTorch, based on the paper "Attention Is All You Need".

## Motivation
The goal of this project is to deeply understand the internal mechanics of transformer models by implementing every core component manually, without using high-level libraries.